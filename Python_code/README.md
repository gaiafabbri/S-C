# Some comments about code

A brief description of the Python code is given below; the project contains a main script, "Program_Start.py", and a series of folders containing the definitions of the functions imported into the main script; the functions are implemented in the files within the folders, divided according to their functionality. The decision to use functions is driven by the fact that some steps are repeated for all models, so functions are implemented to avoid redundancy and also to make the code easier to interpret.

## Program_Start.py
This Python script is designed to perform a series of training and evaluation operations on different machine learning models, comparing them with each other. The process involves the use of convolutional neural networks (CNNs) implemented both with TensorFlow-Keras and PyTorch, a gradient boosting algorithm (BDT), and a deep connected neural network (DNN). The final comparison is done through the creation and visualization of ROC curves for each model.

The user here is prompted to choose which model to start with. The logic behind this is as follows: all four models can be experimented with, but once a model is chosen, it cannot be retried in subsequent prompts. Additionally, pressing button number 5 will display a ROC curve comparing all the executed models. If only one model has been executed, only one ROC curve will be displayed. However, if all four models have been executed, then four ROC curves will be shown. The button 5 also acts as an "exit" button, allowing the user to terminate the program. The dataset is split into training and test sets, and the model is trained and evaluated for each model, except for PyTorch, where the data is first converted into tensors before training and evaluation. After that, the four models are defined. 

For the PyTorch-based model, we utilize the `trained_model` function to train the model, monitoring the time taken for training. Subsequently, we evaluate the model's performance on the test set using the `test_eval` function and generate predictions to compute metrics such as precision, F1 score, and accuracy. Finally, we visualize the ROC curve and the training history curves. Instead, for the Keras-based models (DNN and CNN), we train the model using Keras's `fit` method, monitoring the time taken for training. We then evaluate the model's performance on the test set and compute evaluation metrics, printing the ROC curve and training curves. Lastly, for the XGBoost-based model (BDT), we define and train the model using the "BDT_model" function, while the "BDT_eval" function evaluates its performance, and generates predictions to calculate evaluation metrics. Subsequently, we print the ROC curve and training curves. After each training and evaluation process of the models, parameters such as "f1", "accuracy", "precision", and "training time" are calculated and printed on a table. This table is updated each time with the results obtained from each model through the "table.py" module. Additionally, when button 5 is pressed, ROC curves of the trained models are generated and plotted to perform a comparison.

### 1) DEPENDENCIES
The code relies on multiple Python libraries, including os, tensorflow, numpy, pandas, torch, matplotlib.pyplot, and time. Additionally, it incorporates functions defined in separate Python files, organized within specific directories: "__Evaluation__", "__Models__", and "__DataPreparation__". 
- The "__DataPreparation__" directory contains Python files responsible for various data preprocessing tasks. These files include "Data_Preparation.py" (function: load_and_normalize_images, create_features_labels and apply_shuffle), "PCA.py" (functions: find_optimal_num_components, apply_pca), "Preparing_Dataset.py"(functions: Control_PCA). Each module contains functions for data loading and preprocessing, shuffling, calculating Principal Component Analysis (PCA), and applying PCA directly to a dataset, depending on the ML algorithm in question.
- In the "__Models__" directory, there are individual Python files for different machine learning models, including "model_keras_PCA" (function: keras_PCA), "model_DNN_PCA" (function: DNN_model_PCA), "model_Torch_PCA" (function: torch_PCA), and "model_BDT" (function: BDT_model).
- Within the "__Evaluation__" directory, there are Python files such as "PredictionNN" (functions: eval_Neural_Networks, print_ROC, plot_training_curves_KERAS), "TrainTorch" (functions: accuracy, trained_model, test_eval, predict, torch_eval, plot_training_curves_TORCH), "PredictionBDT" (functions: BDT_eval, print_ROC_BDT, plot_training_curves_BDT), and "Table" (function: save_results_table), each containing multiple functions. These functions handle tasks related to model prediction, PyTorch training, BDT prediction, and result tabulation, respectively.


## 2) The "DataPreparation" folder: 
### 2.1) DATA LOADING & NORMALIZATION
- __Extraction Features()__: The code extracts several variables from the file names: the number of events, stored as event_number, and the height and width of the images, stored as height and width, respectively. These variables serve as inputs for subsequent steps in the code.
- __File Path and Data Loading()__: This functionality is implemented using the "load_and_normalize_images" function. The code takes two inputs: the folder path containing the images and the file name. It utilizes Uproot to open the specified file and loads the data for both signal and background images.
- __Data Normalization()__: Implemented using the "load_and_normalize_images" function, this step calculates the maximum pixel values for both signal and background images. The images are then normalized by dividing each pixel by the calculated maximum value. This ensures that all pixel values are scaled between 0 and 1, making the data comparable and facilitating model training.
  
### 2.2) DATA PREPARATION
In this code section, we prepare the data for machine learning tasks by converting signal and background images into NumPy arrays and defining features and labels.
- __Data Conversion and Dimension Printing()__: Initially, we convert the signal and background images into NumPy arrays, which are stored as "signal_images_numpy" and "background_images_numpy," respectively. This conversion facilitates further processing of the image data. Additionally, we print the dimensions of the resulting NumPy arrays to look the shape of our data.
- __Features and Labels Definition()__: Next, we utilize the "create_features_labels" function to define the features (X) and labels (y) for our machine learning model. The features (X) are generated by concatenating the signal and background data arrays. This concatenation merges the image data into a single array, which serves as the input for our model. Labels (y) are assigned to each data point, with signal data labeled as 0 and background data labeled as 1.

### 2.3) PREPARING DATASET: Principal Component Analysis (PCA)
The dataset preparation is handled by the "Control_PCA" function, which takes features (X), labels (y), image width, and height as inputs and performs the following tasks:
- In the event that the selected model is one of the DNN, CNN with Torch or TensorFlow-Keras, the code will perform PCA on the dataset. This is achieved by invoking the "find_optimal_num_components" and "apply_pca" functions from "PCA.py" and additionally calling the "apply_shuffle" function from "Data_Preparation.py" to shuffle the data.
    - The "__find_optimal_num_components()__" function calculates the optimal number of principal components required to explain a specified percentage (95%) of the total variance in the dataset. It achieves this by fitting a PCA model to the normalized data and computing the cumulative explained variance ratio to determine the number of components needed.
    - The "__apply_pca()__" function applies PCA to the normalized data with the specified number of components (stored in the variable "num_components"). It returns the transformed data after dimensionality reduction.
    - The "__apply_shuffle()__" function shuffles the data to introduce randomness, which helps prevent model overfitting and ensures robustness. It shuffles the data while maintaining the correspondence between features and labels.
- If the model is instead BDT, the X and y datasets are left unaltered and recalled as X_new.
It is worth emphasising that the BDT model does not require data shuffling, since each decision tree is built independently of the order of the data and there is no sequential dependency as in neural networks; this means that the order of the data does not affect the training. On the other hand, in the DNN and CNN methods, the order of the data affects the learning; moreover, the shuffle prevents the model from learning patterns that are only present in a given order of the data.

The function returns the variables "X_new", "y_new", and "n_principal_components". The code is initiated at the outset of each model.

### 3) The "Model" folder
It contains the definitions of the model implemented, together with some comments. In particular the model are defined as:
-__DNN_model_PCA()___ in which the DNN is build with 4 dense layer with ReLU activation function followed by 4 normalization layers; finally there is a dense layer with one neuron and 'sigmoid' activation function which accounts for the final classifcatioon between the two classes
-__BDT_model()__ defines the xgboost classifier and trasforms data to DMatrix format for training and evalutaion;
-__torch_PCA()__ defines three linear layer fully connected followed by the ReLU activation function; the "Reshape" layer transfroms the input according to the number of principal components chosen. The last "Sigmoid" layer is commonly used for binary classification process since it returns an aoutput between 0 and 1 which is the probability to belong to one of the two classes
-__keras_PCA()__" model is composed by an input layer, a convolutional layer, a MaxPooling layre, a Flatten layer to flatten the output and a layer given by the "sigmoid" activation function suitable for a binary classification problem

### 4) The "Evaluation" folder
It implements the function to evaluate the models; it also contains the "table.py" code to store the resulting metrics in a table together with the training time: the higher values of accuracy, precision and f1 score are highlighted.

#### 4.1) Train_Torch functions:
- __accuracy()__ function_: This function computes the accuracy of the model's predictions compared to the target labels. It takes the model's predictions (outputs) and the target labels (targets) as input and returns a scalar value representing the accuracy.
- __trained_model()__: This function manages the model training process. During each epoch, it performs both training and validation of the model. It utilizes a DataLoader to load the training and validation data in mini-batches. During training, it calculates the loss and accuracy of the model on the training data and updates the model's weights using the specified optimizer. During validation, it evaluates the model's performance on the validation data without updating the model's weights. The function returns the trained model and a dictionary containing the loss and accuracy values during training and validation.
- __test_eval()__: This function evaluates the model's performance on the test data. It uses a DataLoader to load the test data in mini-batches. It calculates the loss and accuracy of the model on the test data and prints the results.
- __predict()__: This function generates the model's predictions on the test data. It uses the trained model to make predictions on each mini-batch of test data and returns the predictions as a NumPy array.
- __torch_eval()__: This function computes and returns various evaluation metrics of the model on the test data, including precision, F1 Score, and accuracy. It utilizes the predict function to obtain the model's predictions and compares the predictions with the target labels to calculate the metrics.
- __plot_training_curves_TORCH()__: This function visualizes the loss and accuracy curves during the model training and validation process. It takes a dictionary containing the loss and accuracy values during training and validation as input and plots the corresponding curves using the Matplotlib library.

#### 4.2) Prediction_BDT functions:
- __BDT_eval()__: This function evaluates the performance of the Boosted Decision Trees (BDT) model on the test data. It takes the trained model, the test data (X_test), and their corresponding labels (y_test) as input. The function utilizes the model to make predictions on the test data and calculates the accuracy, precision, and F1 score of the predictions. It returns the model's predictions, the rounded binary predictions, precision, F1 score, and accuracy.
- __print_ROC_BDT()__: This function computes and displays the Receiver Operating Characteristic (ROC) curve and the confusion matrix of the Boosted Decision Trees (BDT) model on the test data. It takes the test labels (y_test), the model's continuous predictions (y_pred), and the rounded binary predictions (y_pred_binary) as input. The function computes the ROC curve using the continuous predictions and visualizes the confusion matrix. It returns the background rejection rate and the signal efficiency.
- __plot_training_curves_BDT()__: This function visualizes the training and test curves of evaluation metrics for the Boosted Decision Trees (BDT) model. It takes the dictionary of evaluation metrics (evals_result) returned during the model training process and plots the log-loss curves for training and testing.


#### 4.3) PredictionNN functions:
- __eval_Neural_Networks()__: This function evaluates the performance of the neural network on the test set. It takes the neural network model, the test data (X_test), and their corresponding labels (y_test) as input. The function utilizes the model's evaluate method to compute the loss and accuracy on the test data. It then makes predictions using the predict method and calculates the precision, F1 score, and accuracy of the predictions. The function returns the continuous predictions, rounded binary predictions, precision, F1 score, and accuracy.
- __print_ROC()__: This function computes and displays the Receiver Operating Characteristic (ROC) curve and the confusion matrix of the neural network model on the test data. It takes the test labels (y_test), the model's continuous predictions (y_pred), and the rounded binary predictions (y_pred_classes) as input. The function calculates the ROC curve using the continuous predictions and visualizes the confusion matrix. It returns the background rejection rate and the signal efficiency.
- __plot_training_curves_KERAS()__: This function visualizes the training and validation curves of the neural network. It takes the history object returned during the neural network training process and plots the accuracy and loss curves for training and validation.

#### 4.4) Table function:
Inside the Table file, the save_results_table function is designed to save the evaluation metrics results of the models (f1, accuracy, precision) and the training time into a Pandas DataFrame, and then draw a table using Matplotlib. Here are the parameters:
- "model_results":  A dictionary containing the evaluation metrics results for each model. The keys of the dictionary are the model names, and the values are tuples containing accuracy, precision, f1 score, and training time.
- "results_df": The Pandas DataFrame containing the models' evaluation results. If it's None (i.e., when the code is run for the first time), a new DataFrame will be created.

The function iterates through the model results in the "model_results" dictionary. For each model, it extracts accuracy, precision, f1 score, and training time from the respective tuple and adds them as a new row to the "results_df" DataFrame. Finally, it draws a table containing the results.

